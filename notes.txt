make sure that slots can scale to be massive (i think that they can and are)

make sure that multiple slots are rendered into the env for the guess, it sure looks like I just have one oblong sphere

check on the input to the nn, and the ground truth.
- we probably want to log-scale distances
- we probably want to clip to nan far away values in the label, so they're not sampled for loss

one option is that the camera isn't pointing in the right direction at all?


im beginning to see that I have no idea how all of this stuff is working and lining up

is my point cloud upside down? am I even comparing it to the right image? how am I supposed to tell?

if I just reveresed it, why is the 3js thing always looking away?

i think that having the point cloud and images seperate doesnt make any sense

i think that i should just be blasting every pixel from the image intot he reference point cloud

i should probably crank up the loss point cloud too.

I think that I should ahve a little like, popup reference for the actual image its mean to be based on
and then a big view with both the point cloud and slots visualized in it.

model.py has truly terrible naming work done.